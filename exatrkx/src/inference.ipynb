{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['TRKXINPUTDIR'] = '/global/cfs/cdirs/m3443/data/trackml-kaggle/train_all' # better change to your copy of the dataset.\n",
    "# os.environ['TRKXOUTPUTDIR'] = '/global/cscratch1/sd/xju/heptrkx/iml2020/run200' # change to your own directory\n",
    "os.environ['TRKXINPUTDIR']=\"/global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts\"\n",
    "os.environ['TRKXOUTPUTDIR']= \"/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/run1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system import\n",
    "import pkg_resources\n",
    "import yaml\n",
    "import pprint\n",
    "import random\n",
    "random.seed(1234)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib widget\n",
    "\n",
    "# 3rd party\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from trackml.dataset import load_event\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# local import\n",
    "# from heptrkx.dataset import event as master\n",
    "from exatrkx import config_dict # for accessing predefined configuration files\n",
    "from exatrkx import outdir_dict # for accessing predefined output directories\n",
    "from exatrkx.src import utils_dir\n",
    "\n",
    "\n",
    "# for preprocessing\n",
    "from exatrkx import FeatureStore\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for embedding\n",
    "from exatrkx import LayerlessEmbedding\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for filtering\n",
    "from exatrkx import VanillaFilter\n",
    "\n",
    "# for GNN\n",
    "import tensorflow as tf\n",
    "from graph_nets import utils_tf\n",
    "from exatrkx import SegmentClassifier\n",
    "import sonnet as snt\n",
    "\n",
    "# for labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import prepare as prepare_labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import clustering as dbscan_clustering\n",
    "\n",
    "# track efficiency\n",
    "from trackml.score import _analyze_tracks\n",
    "from exatrkx.scripts.eval_reco_trkx import make_cmp_plot, pt_configs, eta_configs\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some hyperparameters and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/embedding/checkpoints/epoch=10.ckpt'\n",
    "filter_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/filtering/checkpoints/epoch=92.ckpt'\n",
    "gnn_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/gnn'\n",
    "plots_dir = '/global/homes/c/caditi97/exatrkx-iml2020/exatrkx/src/plots/run1' # needs to change...\n",
    "ckpt_idx = -1 # which GNN checkpoint to load\n",
    "dbscan_epsilon, dbscan_minsamples = 0.25, 2 # hyperparameters for DBScan\n",
    "min_hits = 5 # minimum number of hits associated with a particle to define \"reconstructable particles\"\n",
    "frac_reco_matched, frac_truth_matched = 0.5, 0.5 # parameters for track matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evtid = 1000\n",
    "event_file = os.path.join(utils_dir.inputdir, 'event{:09}'.format(evtid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'adjacent': True,\n",
      "    'cell_information': True,\n",
      "    'endcaps': True,\n",
      "    'layerless': True,\n",
      "    'layerwise': False,\n",
      "    'n_files': 10,\n",
      "    'n_tasks': 1,\n",
      "    'n_workers': 2,\n",
      "    'noise': 0,\n",
      "    'pt_min': 0}\n"
     ]
    }
   ],
   "source": [
    "action = 'build'\n",
    "\n",
    "config_file = pkg_resources.resource_filename(\n",
    "                    \"exatrkx\",\n",
    "                    os.path.join('configs', config_dict[action]))\n",
    "with open(config_file) as f:\n",
    "    b_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(b_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_config['pt_min'] = 0\n",
    "b_config['endcaps'] = True\n",
    "b_config['n_workers'] = 1\n",
    "b_config['n_files'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detector...\n",
      "Detector loaded.\n",
      "Writing outputs to /global/cfs/projectdirs/m3443/usr/caditi97/iml2020/run1/feature_store\n",
      "Preparing 1000\n",
      "Layerless truth graph built for /global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000 with size (2, 123429)\n",
      "Cell features for 1000\n",
      "Loading event /global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000 with a 0 pT cut\n",
      "Writing to  /global/cfs/projectdirs/m3443/usr/caditi97/iml2020/run1/feature_store/1000\n"
     ]
    }
   ],
   "source": [
    "# this cell is only needed for the first run to prodcue the dataset\n",
    "preprocess_dm = FeatureStore(b_config)\n",
    "preprocess_dm.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[103305, 9], event_file=\"/global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000\", hid=[103305], layerless_true_edges=[2, 123429], layers=[103305], pid=[103305], x=[103305, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(os.path.join(utils_dir.feature_outdir, str(evtid)))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'adjacent': False,\n",
      "    'emb_dim': 8,\n",
      "    'emb_hidden': 512,\n",
      "    'endcaps': True,\n",
      "    'factor': 0.3,\n",
      "    'in_channels': 12,\n",
      "    'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml/feature_store_endcaps',\n",
      "    'knn': 20,\n",
      "    'layerless': True,\n",
      "    'layerwise': False,\n",
      "    'lr': 0.002,\n",
      "    'margin': 1,\n",
      "    'max_epochs': 100,\n",
      "    'nb_layer': 6,\n",
      "    'noise': False,\n",
      "    'output_dir': 'global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps',\n",
      "    'overwrite': True,\n",
      "    'patience': 5,\n",
      "    'project': 'EmbeddingStudy',\n",
      "    'pt_min': 0,\n",
      "    'r_train': 1,\n",
      "    'r_val': 0.5,\n",
      "    'randomisation': 2,\n",
      "    'regime': ['rp', 'hnm', 'ci'],\n",
      "    'train_split': [900, 50, 50],\n",
      "    'wandb_save_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data',\n",
      "    'warmup': 500,\n",
      "    'weight': 4}\n"
     ]
    }
   ],
   "source": [
    "e_ckpt = torch.load(embed_ckpt_dir, map_location='cpu')\n",
    "e_config = e_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(e_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_config = e_ckpt['hyper_parameters']\n",
    "e_config['clustering'] = 'build_edges'\n",
    "e_config['knn_val'] = 500\n",
    "e_config['r_val'] = 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the checkpoint and put the model in the evaluation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_model = LayerlessEmbedding(e_config)\n",
    "e_model.load_state_dict(e_ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerlessEmbedding(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (emb_layer): Linear(in_features=512, out_features=8, bias=True)\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each hit to the embedding space, return the embeded parameters for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 1.42 s, total: 5.61 s\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spatial = e_model(torch.cat([data.cell_data, data.x], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From embeddeding space form doublets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r_val = 1.7` and `knn_val = 500` are the hyperparameters to be studied.\n",
    "\n",
    "* `r_val` defines the radius of the clustering method\n",
    "* `knn_val` defines the number of maximum neighbors in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 2.17 s, total: 4.91 s\n",
      "Wall time: 5.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(torch.cuda.is_available()):\n",
    "        spatial = spatial.cuda()\n",
    "\n",
    "e_spatial = utils_torch.build_edges(spatial, e_model.hparams['r_val'], e_model.hparams['knn_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_spatial = e_spatial.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing edges that point from outer region to inner region, which almost removes half of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_dist = torch.sqrt(data.x[:,0]**2 + data.x[:,2]**2) # distance away from origin...\n",
    "e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'adjacent': False,\n",
      "    'batchnorm': False,\n",
      "    'callbacks': [],\n",
      "    'emb_channels': 0,\n",
      "    'endcaps': True,\n",
      "    'factor': 0.3,\n",
      "    'filter_cut': 0.3,\n",
      "    'hidden': 512,\n",
      "    'in_channels': 12,\n",
      "    'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps',\n",
      "    'layerless': True,\n",
      "    'layernorm': True,\n",
      "    'layerwise': False,\n",
      "    'lr': 0.002,\n",
      "    'max_epochs': 100,\n",
      "    'nb_layer': 3,\n",
      "    'noise': False,\n",
      "    'output_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/filter_processed/0_pt_cut_endcaps',\n",
      "    'patience': 8,\n",
      "    'project': 'FilteringStudy',\n",
      "    'pt_min': 0,\n",
      "    'ratio': 2,\n",
      "    'regime': ['ci'],\n",
      "    'train_split': [80, 10, 10],\n",
      "    'val_subset': 0.1,\n",
      "    'wandb_save_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data',\n",
      "    'warmup': 200,\n",
      "    'weight': 2}\n"
     ]
    }
   ],
   "source": [
    "f_ckpt = torch.load(filter_ckpt_dir, map_location='cpu')\n",
    "f_config = f_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(f_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_config['train_split'] = [0, 0, 1]\n",
    "f_config['filter_cut'] = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model = VanillaFilter(f_config)\n",
    "# f_model = f_model.load_from_checkpoint(filter_ckpt_dir, hparams=f_config)\n",
    "f_model.load_state_dict(f_ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaFilter(\n",
       "  (input_layer): Linear(in_features=24, out_features=512, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb = None # embedding information was not used in the filtering stage.\n",
    "output = f_model(torch.cat([data.cell_data, data.x], axis=-1), e_spatial, emb).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot may need some time to load...\n",
    "plt.hist(output.detach().numpy(), );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering network assigns a score to each edge. In the end, edges with socres > `filter_cut` are selected to construct graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = e_spatial[:, output > f_model.hparams['filter_cut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form a graph\n",
    "Now moving TensorFlow for GNN inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = data.x.shape[0]\n",
    "n_edges = edge_list.shape[1]\n",
    "nodes = data.x.numpy().astype(np.float32)\n",
    "edges = np.zeros((n_edges, 1), dtype=np.float32)\n",
    "senders = edge_list[0]\n",
    "receivers = edge_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_datadict = {\n",
    "    \"n_node\": n_nodes,\n",
    "    \"n_edge\": n_edges,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processing_steps_tr = 8\n",
    "optimizer = snt.optimizers.Adam(0.001)\n",
    "model = SegmentClassifier()\n",
    "\n",
    "output_dir = gnn_ckpt_dir\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=10)\n",
    "status = checkpoint.restore(ckpt_manager.checkpoints[ckpt_idx])\n",
    "print(\"Loaded {} checkpoint from {}\".format(ckpt_idx, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outputs_gnn = model(input_graph, num_processing_steps_tr)\n",
    "output_graph = outputs_gnn[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = prepare_labeling(tf.squeeze(output_graph.edges).numpy(), senders, receivers, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tracks = dbscan_clustering(data.hid, input_matrix, dbscan_epsilon, dbscan_minsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, particles, truth = load_event(event_file, parts=['hits', 'particles', 'truth'])\n",
    "hits = hits.merge(truth, on='hit_id', how='left')\n",
    "hits = hits[hits.particle_id > 0] # remove noise hits\n",
    "hits = hits.merge(particles, on='particle_id', how='left')\n",
    "hits = hits[hits.nhits >= min_hits]\n",
    "particles = particles[particles.nhits >= min_hits]\n",
    "par_pt = np.sqrt(particles.px**2 + particles.py**2)\n",
    "momentum = np.sqrt(particles.px**2 + particles.py**2 + particles.pz**2)\n",
    "ptheta = np.arccos(particles.pz/momentum)\n",
    "peta = -np.log(np.tan(0.5*ptheta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = _analyze_tracks(hits, predict_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_rec = np.true_divide(tracks['major_nhits'], tracks['nhits'])\n",
    "purity_maj = np.true_divide(tracks['major_nhits'], tracks['major_particle_nhits'])\n",
    "good_track = (frac_reco_matched < purity_rec) & (frac_truth_matched < purity_maj)\n",
    "\n",
    "matched_pids = tracks[good_track].major_particle_id.values\n",
    "score = tracks['major_weight'][good_track].sum()\n",
    "\n",
    "n_recotable_trkx = particles.shape[0]\n",
    "n_reco_trkx = tracks.shape[0]\n",
    "n_good_recos = np.sum(good_track)\n",
    "matched_idx = particles.particle_id.isin(matched_pids).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed {} events from {}\".format(evtid, utils_dir.inputdir))\n",
    "print(\"Reconstructable tracks:         {}\".format(n_recotable_trkx))\n",
    "print(\"Reconstructed tracks:           {}\".format(n_reco_trkx))\n",
    "print(\"Reconstructable tracks Matched: {}\".format(n_good_recos))\n",
    "print(\"Tracking efficiency:            {:.4f}\".format(n_good_recos/n_recotable_trkx))\n",
    "print(\"Tracking purity:               {:.4f}\".format(n_good_recos/n_reco_trkx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn = partial(make_cmp_plot, xlegend=\"Matched\", ylegend=\"Reconstructable\",\n",
    "                    ylabel=\"Events\", ratio_label='Track efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(par_pt[matched_idx], par_pt,\n",
    "                 configs=pt_configs,\n",
    "                 xlabel=\"pT [GeV]\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_pt\".format(evtid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(peta[matched_idx], peta,\n",
    "                 configs=eta_configs,\n",
    "                 xlabel=r\"$\\eta$\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_eta\".format(evtid)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-iml",
   "language": "python",
   "name": "exatrkx-iml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
