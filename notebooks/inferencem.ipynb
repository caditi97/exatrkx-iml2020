{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['TRKXINPUTDIR'] = '/global/cfs/cdirs/m3443/data/trackml-kaggle/train_all' # better change to your copy of the dataset.\n",
    "# os.environ['TRKXOUTPUTDIR'] = '/global/cscratch1/sd/xju/heptrkx/iml2020/run200' # change to your own directory\n",
    "os.environ['TRKXINPUTDIR']=\"/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/\"\n",
    "os.environ['TRKXOUTPUTDIR']= \"/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/noise1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system import\n",
    "import pkg_resources\n",
    "import yaml\n",
    "import pprint\n",
    "import random\n",
    "random.seed(1234)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib widget\n",
    "\n",
    "# 3rd party\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from trackml.dataset import load_event\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# local import\n",
    "# from heptrkx.dataset import event as master\n",
    "from exatrkx import config_dict # for accessing predefined configuration files\n",
    "from exatrkx import outdir_dict # for accessing predefined output directories\n",
    "from exatrkx.src import utils_dir\n",
    "\n",
    "\n",
    "# for preprocessing\n",
    "from exatrkx import FeatureStore\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for embedding\n",
    "from exatrkx import LayerlessEmbedding\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for filtering\n",
    "from exatrkx import VanillaFilter\n",
    "\n",
    "# for GNN\n",
    "import tensorflow as tf\n",
    "from graph_nets import utils_tf\n",
    "from exatrkx import SegmentClassifier\n",
    "import sonnet as snt\n",
    "\n",
    "# for labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import prepare as prepare_labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import clustering as dbscan_clustering\n",
    "\n",
    "# track efficiency\n",
    "from trackml.score import _analyze_tracks\n",
    "from exatrkx.scripts.eval_reco_trkx import make_cmp_plot, pt_configs, eta_configs\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some hyperparameters and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/embedding/checkpoints/epoch=10.ckpt'\n",
    "filter_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/filtering/checkpoints/epoch=92.ckpt'\n",
    "gnn_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/gnn'\n",
    "plots_dir = '/global/homes/c/caditi97/exatrkx-iml2020/exatrkx/src/plots/noise1' # needs to change...\n",
    "ckpt_idx = -1 # which GNN checkpoint to load\n",
    "dbscan_epsilon, dbscan_minsamples = 0.25, 2 # hyperparameters for DBScan\n",
    "min_hits = 5 # minimum number of hits associated with a particle to define \"reconstructable particles\"\n",
    "frac_reco_matched, frac_truth_matched = 0.5, 0.5 # parameters for track matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evtid = 1000\n",
    "event_file = os.path.join(utils_dir.inputdir, 'event{:09}'.format(evtid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = 'build'\n",
    "\n",
    "# config_file = pkg_resources.resource_filename(\n",
    "#                     \"exatrkx\",\n",
    "#                     os.path.join('configs', config_dict[action]))\n",
    "# with open(config_file) as f:\n",
    "#     b_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "# pp.pprint(b_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_config['pt_min'] = 0\n",
    "# b_config['endcaps'] = True\n",
    "# b_config['n_workers'] = 1\n",
    "# b_config['n_files'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is only needed for the first run to prodcue the dataset\n",
    "# preprocess_dm = FeatureStore(b_config)\n",
    "# preprocess_dm.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[120939, 9], event_file=\"/global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000\", hid=[120939], layerless_true_edges=[2, 6455778], layers=[120939], pid=[120939], x=[120939, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load('/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/1000')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'adjacent': False,\n",
      "    'emb_dim': 8,\n",
      "    'emb_hidden': 512,\n",
      "    'endcaps': True,\n",
      "    'factor': 0.3,\n",
      "    'in_channels': 12,\n",
      "    'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml/feature_store_endcaps',\n",
      "    'knn': 20,\n",
      "    'layerless': True,\n",
      "    'layerwise': False,\n",
      "    'lr': 0.002,\n",
      "    'margin': 1,\n",
      "    'max_epochs': 100,\n",
      "    'nb_layer': 6,\n",
      "    'noise': False,\n",
      "    'output_dir': 'global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps',\n",
      "    'overwrite': True,\n",
      "    'patience': 5,\n",
      "    'project': 'EmbeddingStudy',\n",
      "    'pt_min': 0,\n",
      "    'r_train': 1,\n",
      "    'r_val': 0.5,\n",
      "    'randomisation': 2,\n",
      "    'regime': ['rp', 'hnm', 'ci'],\n",
      "    'train_split': [900, 50, 50],\n",
      "    'wandb_save_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data',\n",
      "    'warmup': 500,\n",
      "    'weight': 4}\n"
     ]
    }
   ],
   "source": [
    "e_ckpt = torch.load(embed_ckpt_dir, map_location='cpu')\n",
    "e_config = e_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(e_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_config = e_ckpt['hyper_parameters']\n",
    "e_config['clustering'] = 'build_edges'\n",
    "e_config['knn_val'] = 500\n",
    "e_config['r_val'] = 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the checkpoint and put the model in the evaluation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_model = LayerlessEmbedding(e_config)\n",
    "e_model.load_state_dict(e_ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerlessEmbedding(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (emb_layer): Linear(in_features=512, out_features=8, bias=True)\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each hit to the embedding space, return the embeded parameters for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 3.68 s, total: 25.2 s\n",
      "Wall time: 973 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spatial = e_model(torch.cat([data.cell_data, data.x], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From embeddeding space form doublets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r_val = 1.7` and `knn_val = 500` are the hyperparameters to be studied.\n",
    "\n",
    "* `r_val` defines the radius of the clustering method\n",
    "* `knn_val` defines the number of maximum neighbors in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 57s, sys: 4.31 s, total: 18min 2s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(torch.cuda.is_available()):\n",
    "        spatial = spatial.cuda()\n",
    "\n",
    "e_spatial = utils_torch.build_edges(spatial, e_model.hparams['r_val'], e_model.hparams['knn_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_spatial = e_spatial.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing edges that point from outer region to inner region, which almost removes half of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_dist = torch.sqrt(data.x[:,0]**2 + data.x[:,2]**2) # distance away from origin...\n",
    "e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'adjacent': False,\n",
      "    'batchnorm': False,\n",
      "    'callbacks': [],\n",
      "    'emb_channels': 0,\n",
      "    'endcaps': True,\n",
      "    'factor': 0.3,\n",
      "    'filter_cut': 0.3,\n",
      "    'hidden': 512,\n",
      "    'in_channels': 12,\n",
      "    'input_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps',\n",
      "    'layerless': True,\n",
      "    'layernorm': True,\n",
      "    'layerwise': False,\n",
      "    'lr': 0.002,\n",
      "    'max_epochs': 100,\n",
      "    'nb_layer': 3,\n",
      "    'noise': False,\n",
      "    'output_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/filter_processed/0_pt_cut_endcaps',\n",
      "    'patience': 8,\n",
      "    'project': 'FilteringStudy',\n",
      "    'pt_min': 0,\n",
      "    'ratio': 2,\n",
      "    'regime': ['ci'],\n",
      "    'train_split': [80, 10, 10],\n",
      "    'val_subset': 0.1,\n",
      "    'wandb_save_dir': '/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data',\n",
      "    'warmup': 200,\n",
      "    'weight': 2}\n"
     ]
    }
   ],
   "source": [
    "f_ckpt = torch.load(filter_ckpt_dir, map_location='cpu')\n",
    "f_config = f_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(f_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_config['train_split'] = [0, 0, 1]\n",
    "f_config['filter_cut'] = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model = VanillaFilter(f_config)\n",
    "# f_model = f_model.load_from_checkpoint(filter_ckpt_dir, hparams=f_config)\n",
    "f_model.load_state_dict(f_ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaFilter(\n",
       "  (input_layer): Linear(in_features=24, out_features=512, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 16s, sys: 5min 2s, total: 17min 18s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb = None # embedding information was not used in the filtering stage.\n",
    "output = f_model(torch.cat([data.cell_data, data.x], axis=-1), e_spatial, emb).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14602261]), (2, 14602261))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this plot may need some time to load...\n",
    "plt.hist(output.detach().numpy(), );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering network assigns a score to each edge. In the end, edges with socres > `filter_cut` are selected to construct graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = e_spatial[:, output > f_model.hparams['filter_cut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2388916)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form a graph\n",
    "Now moving TensorFlow for GNN inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = data.x.shape[0]\n",
    "n_edges = edge_list.shape[1]\n",
    "nodes = data.x.numpy().astype(np.float32)\n",
    "edges = np.zeros((n_edges, 1), dtype=np.float32)\n",
    "senders = edge_list[0]\n",
    "receivers = edge_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_datadict = {\n",
    "    \"n_node\": n_nodes,\n",
    "    \"n_edge\": n_edges,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded -1 checkpoint from /global/cfs/cdirs/m3443/data/lightning_models/gnn\n"
     ]
    }
   ],
   "source": [
    "num_processing_steps_tr = 8\n",
    "optimizer = snt.optimizers.Adam(0.001)\n",
    "model = SegmentClassifier()\n",
    "\n",
    "output_dir = gnn_ckpt_dir\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=10)\n",
    "status = checkpoint.restore(ckpt_manager.checkpoints[ckpt_idx])\n",
    "print(\"Loaded {} checkpoint from {}\".format(ckpt_idx, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outputs_gnn = model(input_graph, num_processing_steps_tr)\n",
    "output_graph = outputs_gnn[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = prepare_labeling(tf.squeeze(output_graph.edges).numpy(), senders, receivers, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tracks = dbscan_clustering(data.hid, input_matrix, dbscan_epsilon, dbscan_minsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, particles, truth = load_event('/global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000', parts=['hits', 'particles', 'truth'])\n",
    "hits = hits.merge(truth, on='hit_id', how='left')\n",
    "hits = hits[hits.particle_id > 0] # remove noise hits\n",
    "hits = hits.merge(particles, on='particle_id', how='left')\n",
    "hits = hits[hits.nhits >= min_hits]\n",
    "particles = particles[particles.nhits >= min_hits]\n",
    "par_pt = np.sqrt(particles.px**2 + particles.py**2)\n",
    "momentum = np.sqrt(particles.px**2 + particles.py**2 + particles.pz**2)\n",
    "ptheta = np.arccos(particles.pz/momentum)\n",
    "peta = -np.log(np.tan(0.5*ptheta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = _analyze_tracks(hits, predict_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_rec = np.true_divide(tracks['major_nhits'], tracks['nhits'])\n",
    "purity_maj = np.true_divide(tracks['major_nhits'], tracks['major_particle_nhits'])\n",
    "good_track = (frac_reco_matched < purity_rec) & (frac_truth_matched < purity_maj)\n",
    "\n",
    "matched_pids = tracks[good_track].major_particle_id.values\n",
    "score = tracks['major_weight'][good_track].sum()\n",
    "\n",
    "n_recotable_trkx = particles.shape[0]\n",
    "n_reco_trkx = tracks.shape[0]\n",
    "n_good_recos = np.sum(good_track)\n",
    "matched_idx = particles.particle_id.isin(matched_pids).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed {} events from {}\".format(evtid, utils_dir.inputdir))\n",
    "print(\"Reconstructable tracks:         {}\".format(n_recotable_trkx))\n",
    "print(\"Reconstructed tracks:           {}\".format(n_reco_trkx))\n",
    "print(\"Reconstructable tracks Matched: {}\".format(n_good_recos))\n",
    "print(\"Tracking efficiency:            {:.4f}\".format(n_good_recos/n_recotable_trkx))\n",
    "print(\"Tracking purity:               {:.4f}\".format(n_good_recos/n_reco_trkx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn = partial(make_cmp_plot, xlegend=\"Matched\", ylegend=\"Reconstructable\",\n",
    "                    ylabel=\"Events\", ratio_label='Track efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(par_pt[matched_idx], par_pt,\n",
    "                 configs=pt_configs,\n",
    "                 xlabel=\"pT [GeV]\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_pt\".format(evtid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(peta[matched_idx], peta,\n",
    "                 configs=eta_configs,\n",
    "                 xlabel=r\"$\\eta$\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_eta\".format(evtid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-iml",
   "language": "python",
   "name": "exatrkx-iml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
