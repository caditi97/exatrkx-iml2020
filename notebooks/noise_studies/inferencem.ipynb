{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['TRKXINPUTDIR'] = '/global/cfs/cdirs/m3443/data/trackml-kaggle/train_all' # better change to your copy of the dataset.\n",
    "# os.environ['TRKXOUTPUTDIR'] = '/global/cscratch1/sd/xju/heptrkx/iml2020/run200' # change to your own directory\n",
    "os.environ['TRKXINPUTDIR']=\"/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/\"\n",
    "os.environ['TRKXOUTPUTDIR']= \"/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/noise1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system import\n",
    "import pkg_resources\n",
    "import yaml\n",
    "import pprint\n",
    "import random\n",
    "random.seed(1234)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib widget\n",
    "\n",
    "# 3rd party\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from trackml.dataset import load_event\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# local import\n",
    "# from heptrkx.dataset import event as master\n",
    "from exatrkx import config_dict # for accessing predefined configuration files\n",
    "from exatrkx import outdir_dict # for accessing predefined output directories\n",
    "from exatrkx.src import utils_dir\n",
    "\n",
    "\n",
    "# for preprocessing\n",
    "from exatrkx import FeatureStore\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for embedding\n",
    "from exatrkx import LayerlessEmbedding\n",
    "from exatrkx.src import utils_torch\n",
    "\n",
    "# for filtering\n",
    "from exatrkx import VanillaFilter\n",
    "\n",
    "# for GNN\n",
    "import tensorflow as tf\n",
    "from graph_nets import utils_tf\n",
    "from exatrkx import SegmentClassifier\n",
    "import sonnet as snt\n",
    "\n",
    "# for labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import prepare as prepare_labeling\n",
    "from exatrkx.scripts.tracks_from_gnn import clustering as dbscan_clustering\n",
    "\n",
    "# track efficiency\n",
    "from trackml.score import _analyze_tracks\n",
    "from exatrkx.scripts.eval_reco_trkx import make_cmp_plot, pt_configs, eta_configs\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some hyperparameters and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/embedding/checkpoints/epoch=10.ckpt'\n",
    "filter_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/filtering/checkpoints/epoch=92.ckpt'\n",
    "gnn_ckpt_dir = '/global/cfs/cdirs/m3443/data/lightning_models/gnn'\n",
    "plots_dir = '/global/homes/c/caditi97/exatrkx-iml2020/exatrkx/src/plots/noise1' # needs to change...\n",
    "ckpt_idx = -1 # which GNN checkpoint to load\n",
    "dbscan_epsilon, dbscan_minsamples = 0.25, 2 # hyperparameters for DBScan\n",
    "min_hits = 5 # minimum number of hits associated with a particle to define \"reconstructable particles\"\n",
    "frac_reco_matched, frac_truth_matched = 0.5, 0.5 # parameters for track matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evtid = 1000\n",
    "event_file = os.path.join(utils_dir.inputdir, 'event{:09}'.format(evtid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = 'build'\n",
    "\n",
    "# config_file = pkg_resources.resource_filename(\n",
    "#                     \"exatrkx\",\n",
    "#                     os.path.join('configs', config_dict[action]))\n",
    "# with open(config_file) as f:\n",
    "#     b_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "# pp.pprint(b_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_config['pt_min'] = 0\n",
    "# b_config['endcaps'] = True\n",
    "# b_config['n_workers'] = 1\n",
    "# b_config['n_files'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is only needed for the first run to prodcue the dataset\n",
    "# preprocess_dm = FeatureStore(b_config)\n",
    "# preprocess_dm.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/1000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b718ca03a495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/1000'"
     ]
    }
   ],
   "source": [
    "data = torch.load('/global/cfs/projectdirs/m3443/usr/caditi97/iml2020/out1/feature_store/1000')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ckpt = torch.load(embed_ckpt_dir, map_location='cpu')\n",
    "e_config = e_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(e_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_config = e_ckpt['hyper_parameters']\n",
    "e_config['clustering'] = 'build_edges'\n",
    "e_config['knn_val'] = 500\n",
    "e_config['r_val'] = 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the checkpoint and put the model in the evaluation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_model = LayerlessEmbedding(e_config)\n",
    "e_model.load_state_dict(e_ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each hit to the embedding space, return the embeded parameters for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial = e_model(torch.cat([data.cell_data, data.x], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From embeddeding space form doublets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r_val = 1.7` and `knn_val = 500` are the hyperparameters to be studied.\n",
    "\n",
    "* `r_val` defines the radius of the clustering method\n",
    "* `knn_val` defines the number of maximum neighbors in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if(torch.cuda.is_available()):\n",
    "        spatial = spatial.cuda()\n",
    "\n",
    "e_spatial = utils_torch.build_edges(spatial, e_model.hparams['r_val'], e_model.hparams['knn_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_spatial = e_spatial.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing edges that point from outer region to inner region, which almost removes half of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_dist = torch.sqrt(data.x[:,0]**2 + data.x[:,2]**2) # distance away from origin...\n",
    "e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ckpt = torch.load(filter_ckpt_dir, map_location='cpu')\n",
    "f_config = f_ckpt['hyper_parameters']\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(f_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_config['train_split'] = [0, 0, 1]\n",
    "f_config['filter_cut'] = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model = VanillaFilter(f_config)\n",
    "# f_model = f_model.load_from_checkpoint(filter_ckpt_dir, hparams=f_config)\n",
    "f_model.load_state_dict(f_ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb = None # embedding information was not used in the filtering stage.\n",
    "output = f_model(torch.cat([data.cell_data, data.x], axis=-1), e_spatial, emb).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot may need some time to load...\n",
    "plt.hist(output.detach().numpy(), );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering network assigns a score to each edge. In the end, edges with socres > `filter_cut` are selected to construct graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = e_spatial[:, output > f_model.hparams['filter_cut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form a graph\n",
    "Now moving TensorFlow for GNN inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = data.x.shape[0]\n",
    "n_edges = edge_list.shape[1]\n",
    "nodes = data.x.numpy().astype(np.float32)\n",
    "edges = np.zeros((n_edges, 1), dtype=np.float32)\n",
    "senders = edge_list[0]\n",
    "receivers = edge_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_datadict = {\n",
    "    \"n_node\": n_nodes,\n",
    "    \"n_edge\": n_edges,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processing_steps_tr = 8\n",
    "optimizer = snt.optimizers.Adam(0.001)\n",
    "model = SegmentClassifier()\n",
    "\n",
    "output_dir = gnn_ckpt_dir\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=10)\n",
    "status = checkpoint.restore(ckpt_manager.checkpoints[ckpt_idx])\n",
    "print(\"Loaded {} checkpoint from {}\".format(ckpt_idx, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outputs_gnn = model(input_graph, num_processing_steps_tr)\n",
    "output_graph = outputs_gnn[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = prepare_labeling(tf.squeeze(output_graph.edges).numpy(), senders, receivers, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tracks = dbscan_clustering(data.hid, input_matrix, dbscan_epsilon, dbscan_minsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, particles, truth = load_event('/global/cfs/cdirs/m3443/data/trackml-kaggle/train_10evts/event000001000', parts=['hits', 'particles', 'truth'])\n",
    "hits = hits.merge(truth, on='hit_id', how='left')\n",
    "hits = hits[hits.particle_id > 0] # remove noise hits\n",
    "hits = hits.merge(particles, on='particle_id', how='left')\n",
    "hits = hits[hits.nhits >= min_hits]\n",
    "particles = particles[particles.nhits >= min_hits]\n",
    "par_pt = np.sqrt(particles.px**2 + particles.py**2)\n",
    "momentum = np.sqrt(particles.px**2 + particles.py**2 + particles.pz**2)\n",
    "ptheta = np.arccos(particles.pz/momentum)\n",
    "peta = -np.log(np.tan(0.5*ptheta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = _analyze_tracks(hits, predict_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_rec = np.true_divide(tracks['major_nhits'], tracks['nhits'])\n",
    "purity_maj = np.true_divide(tracks['major_nhits'], tracks['major_particle_nhits'])\n",
    "good_track = (frac_reco_matched < purity_rec) & (frac_truth_matched < purity_maj)\n",
    "\n",
    "matched_pids = tracks[good_track].major_particle_id.values\n",
    "score = tracks['major_weight'][good_track].sum()\n",
    "\n",
    "n_recotable_trkx = particles.shape[0]\n",
    "n_reco_trkx = tracks.shape[0]\n",
    "n_good_recos = np.sum(good_track)\n",
    "matched_idx = particles.particle_id.isin(matched_pids).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed {} events from {}\".format(evtid, utils_dir.inputdir))\n",
    "print(\"Reconstructable tracks:         {}\".format(n_recotable_trkx))\n",
    "print(\"Reconstructed tracks:           {}\".format(n_reco_trkx))\n",
    "print(\"Reconstructable tracks Matched: {}\".format(n_good_recos))\n",
    "print(\"Tracking efficiency:            {:.4f}\".format(n_good_recos/n_recotable_trkx))\n",
    "print(\"Tracking purity:               {:.4f}\".format(n_good_recos/n_reco_trkx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn = partial(make_cmp_plot, xlegend=\"Matched\", ylegend=\"Reconstructable\",\n",
    "                    ylabel=\"Events\", ratio_label='Track efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(par_pt[matched_idx], par_pt,\n",
    "                 configs=pt_configs,\n",
    "                 xlabel=\"pT [GeV]\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_pt\".format(evtid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cmp_plot_fn(peta[matched_idx], peta,\n",
    "                 configs=eta_configs,\n",
    "                 xlabel=r\"$\\eta$\",\n",
    "                 outname=os.path.join(plots_dir, \"{}_eta\".format(evtid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-iml",
   "language": "python",
   "name": "exatrkx-iml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
